{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook is to analyze the search results and the predicted path results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Search results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.1 analyze the completeness of the search results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# each query should get 100 results\n",
    "import os\n",
    "# change the working directory to the root of the project\n",
    "os.chdir(\"/home/aiops/zhuty/tinyllama/processing/graphs\")\n",
    "import tqdm\n",
    "import argparse\n",
    "from utils import read_trec_results\n",
    "version = \"20b\"\n",
    "result_dir = f\"/home/aiops/zhuty/ret_pretraining_data/redpajama_{version}_id_added/bm25_search_results/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST = False\n",
    "# read result from all chunks\n",
    "result_dict = {}\n",
    "for i in tqdm.tqdm(list(range(0, 89)) + ['search_fail_queries_added'] + ['missing_queries']):\n",
    "    if TEST and i > 10:\n",
    "        break\n",
    "    file_path = os.path.join(result_dir, \"chunk_{i}.result.txt\".format(i=i))\n",
    "    result_dict.update(read_trec_results(file_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "# Print the results\n",
    "for query_id, docs in result_dict.items():\n",
    "    print(f\"Query {query_id}:\")\n",
    "    count += 1\n",
    "    for doc in docs[:10]:\n",
    "        print(f\"  Doc ID: {doc['doc_id']}, Score: {doc['score']}, Rank: {doc['rank']}\")\n",
    "    if  count > 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing the completeness of the search results, each query should get 100 results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# count how many docs have itself as the top1 neighbor\n",
    "count = 0\n",
    "result_lengths = []\n",
    "problematic_queries = []\n",
    "for query_id, docs in result_dict.items():\n",
    "    if docs[0]['doc_id'] == query_id:\n",
    "        count += 1\n",
    "    result_lengths.append(len(docs))\n",
    "    if len(docs) < 100:\n",
    "        problematic_queries.append(query_id)\n",
    "print(\"Number of queries that have itself as the top1 neighbor:\", count, f\"percentage: {count/len(result_dict) *100:.2f}%\")\n",
    "print(Counter(result_lengths))\n",
    "print(\"Number of queries that have less than 100 results:\", len(problematic_queries), f\"percentage: {len(problematic_queries)/len(result_dict) *100:.2f}%\")\n",
    "problematic_queries[:10]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sequence_set = set()\n",
    "for i in range(0, 89):\n",
    "    for j in range(0, 10000):\n",
    "        sequence_set.add(\"{i}_{j}\".format(i=i, j=j))\n",
    "\n",
    "missing_queries = []\n",
    "for query_id in sequence_set:\n",
    "    if query_id not in result_dict:\n",
    "        missing_queries.append(query_id)\n",
    "# missing queries is problematic ==> it means that it cannot even search itself ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of queries that are missing:\", len(missing_queries), f\"percentage: {len(missing_queries)/len(sequence_set) *100:.2f}%\")\n",
    "print(\"missing queries:\", missing_queries[:10])\n",
    "newly_added_search_fail_queries = set(list(problematic_queries) + missing_queries)\n",
    "print(\"Number of newly added search fail queries:\", len(newly_added_search_fail_queries))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "def get_content(query_id, corpus_path=\"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/queries\"):\n",
    "    chunk_id, seq_id = query_id.split(\"_\")\n",
    "    base_path = corpus_path\n",
    "    jsonl_file = os.path.join(base_path, \"chunk_{}.jsonl\".format(chunk_id))\n",
    "    with open(jsonl_file, \"r\") as f:\n",
    "        # directly go the line\n",
    "        line = f.readlines()[int(seq_id)]\n",
    "        data = json.loads(line)\n",
    "        assert data[\"id\"] == query_id\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# if the newly added queries are not empty, then we need to rerun the search for them\n",
    "\n",
    "import json\n",
    "\n",
    "to_write_data = []\n",
    "not_searched_query_ids = sorted(missing_queries)\n",
    "for docid in tqdm.tqdm(not_searched_query_ids, total=len(not_searched_query_ids)):\n",
    "    chunk_id, seq_id = docid.split(\"_\")\n",
    "    base_path = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/queries\"\n",
    "    jsonl_file = os.path.join(base_path, \"chunk_{}.jsonl\".format(chunk_id))\n",
    "    with open(jsonl_file, \"r\") as f:\n",
    "        # directly go the line\n",
    "        line = f.readlines()[int(seq_id)]\n",
    "        data = json.loads(line)\n",
    "        assert data[\"id\"] == docid\n",
    "\n",
    "        if len(data['title']) > 1500:\n",
    "            print(\"problematic docid\", docid)\n",
    "            print(data['title'])\n",
    "            print(len(data['title'].split()))\n",
    "            data['title'] = data['title'][-1500:]\n",
    "        to_write_data.append(data)\n",
    "\n",
    "        # a slower version\n",
    "        # for line in f:\n",
    "        #     line = line.strip()\n",
    "        #     if line:\n",
    "        #         data = json.loads(line)\n",
    "        #         if data[\"id\"] == docid:\n",
    "        #             # print(data)\n",
    "        #             # print(len(data['title'].split()))\n",
    "        #             to_write_data.append(data)\n",
    "        #             break\n",
    "# write to jsonl\n",
    "with open(os.path.join(base_path, \"chunk_missing_queries.jsonl\"), \"w\") as f:\n",
    "    for data in to_write_data:\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the distribution of the scores of the top1 neighbors, compared to the scores of other neighbors in top 10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "top_1_scores = [min(300, docs[0]['score']) for docs in result_dict.values()] # add min to avoid outliers\n",
    "others_scores = [min(300, docs[1]['score']) for docs in result_dict.values() if len(docs) > 1]\n",
    "plt.hist(top_1_scores, bins=100, alpha=0.5, label='top1')\n",
    "plt.hist(others_scores, bins=100, alpha=0.5, label='others')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Distribution of the scores of the top1 neighbors, compared to the scores of top2 neighbors\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted(top_1_scores, reverse=True)[:1000000][-10:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create different versions of adjacency list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add the top_k neighbors as edges\n",
    "top_k = 100\n",
    "low_score_threshold = 30\n",
    "adj_lst = {}\n",
    "num_edges = 0\n",
    "for query_id, docs in tqdm.tqdm(result_dict.items()):\n",
    "    adj_lst[query_id] = []\n",
    "    for doc in docs[:top_k + 1]:\n",
    "        if doc['doc_id'] == query_id:\n",
    "            # neighbor is the query itself, continue\n",
    "            continue\n",
    "        if doc['score'] < low_score_threshold:\n",
    "            # filter out the low score neighbors\n",
    "            continue\n",
    "        adj_lst[query_id].append((doc['doc_id'], doc['score']))\n",
    "        num_edges += 1\n",
    "print(\"Number of edges:\", num_edges)\n",
    "# get the average out degree\n",
    "print(\"Average out degree:\", num_edges / len(sequence_set))\n",
    "print(\"max out degree:\", max([len(neighbors) for neighbors in adj_lst.values()]))\n",
    "print(\"std out degree:\", np.std([len(neighbors) for neighbors in adj_lst.values()]))\n",
    "# get the average in degree\n",
    "in_degree = {}\n",
    "for query_id, neighbors in tqdm.tqdm(adj_lst.items()):\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor[0] not in in_degree:\n",
    "            in_degree[neighbor[0]] = 0\n",
    "        in_degree[neighbor[0]] += 1\n",
    "print(\"Average in degree:\", sum(in_degree.values()) / len(sequence_set))\n",
    "print(\"max in degree:\", max(in_degree.values()))\n",
    "print(\"min in degree:\", min(in_degree.values()))\n",
    "print(\"std in degree:\", np.std(list(in_degree.values())))\n",
    "\n",
    "json.dump(adj_lst, open(f\"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/adj_lists/adj_lst_top_{top_k}.json\", \"w\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, the adjacency list is complete. Please go ahead and run graph_traversal.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 2: analyze the traversed path results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_files = 'Saving result to /home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/traversal_paths/result_path_adj_lst_top_100_all_degree_min_degree_selection_20240103_130057.json'\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def find_latest_file(directory, prefix, directed):\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    if directed:\n",
    "        files = [x for x in files if 'undirected' not in x ]\n",
    "    else:\n",
    "        files = [x for x in files if 'undirected'  in x ]\n",
    "\n",
    "    # Filter files based on the prefix and extract timestamps\n",
    "    timestamped_files = []\n",
    "    for file in files:\n",
    "        if file.startswith(prefix):\n",
    "            match = re.search(r'(\\d{8}_\\d{6})', file)\n",
    "            if match:\n",
    "                timestamp = match.group(1)\n",
    "                timestamped_files.append((file, timestamp))\n",
    "\n",
    "    # Check if there are any matched files\n",
    "    if not timestamped_files:\n",
    "        return None\n",
    "\n",
    "    # Convert timestamps to datetime objects and find the latest file\n",
    "    timestamped_files.sort(key=lambda x: datetime.strptime(x[1], '%Y%m%d_%H%M%S'), reverse=True)\n",
    "    return timestamped_files[0][0]\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def get_path_length_statistics(paths):\n",
    "    # print the length of the paths\n",
    "    print(\"Number of paths:\", len(paths))\n",
    "    path_lengths = [len(path) for path in paths]\n",
    "    print(Counter(path_lengths))\n",
    "    # get statistics of the path lengths\n",
    "    print(\"Average path length:\", sum(path_lengths) / len(path_lengths))\n",
    "    print(\"Max path length:\", max(path_lengths))\n",
    "    print(\"Min path length:\", min(path_lengths))\n",
    "    print(\"std path length:\", np.std(path_lengths))\n",
    "    stats_dict = {\n",
    "        \"num_paths\": len(paths),\n",
    "        \"avg_path_length\": sum(path_lengths) / len(path_lengths),\n",
    "        \"max_path_length\": max(path_lengths),\n",
    "        \"min_path_length\": min(path_lengths),\n",
    "        \"std_path_length\": np.std(path_lengths)\n",
    "    }\n",
    "    return stats_dict\n",
    "\n",
    "\n",
    "\n",
    "row_lst = []\n",
    "paths_dir = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/traversal_paths\"\n",
    "# for k in 1 3 5 10 20 ; do\n",
    "for k in [1,3,5,10,20,100]:\n",
    "  for node_selection in [\"random\", \"min_degree\", \"max_degree\"]:\n",
    "    for degree_measure in [\"in\" ,\"out\" ,\"all\" ]:\n",
    "        for directed in [True, False]:\n",
    "            latest_path_file = find_latest_file(directory = paths_dir,\n",
    "                                                prefix = f\"result_path_adj_lst_top_{k}_{degree_measure}_degree_{node_selection}_selection\",\n",
    "                                                directed=directed)\n",
    "            print(latest_path_file)\n",
    "            paths = json.load(open(os.path.join(paths_dir, latest_path_file)),)\n",
    "            stats_dict = get_path_length_statistics(paths)\n",
    "            stats_dict['name'] = latest_path_file\n",
    "            row_lst.append(stats_dict)\n",
    "\n",
    "# create a dataframe\n",
    "df = pd.DataFrame(row_lst)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the average path length for each name in the df\n",
    "name_avg_length = zip(df['name'], df['avg_path_length'])\n",
    "name_avg_length = sorted(name_avg_length, key=lambda x: x[1])\n",
    "for name, avg_length in name_avg_length:\n",
    "    print(name, avg_length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# adj_lst = json.load(open(\"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/adj_lists/adj_lst_top_1.json\", \"r\"))\n",
    "# adj_lst = json.load(open(\"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/adj_lists/adj_lst_top_3.json\", \"r\"))\n",
    "adj_lst = json.load(open(\"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/adj_lists/adj_lst_top_5.json\", \"r\"))\n",
    "# path_file = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/traversal_paths/result_path_adj_lst_top_1_20240103_074215.json\"\n",
    "# path_file = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/traversal_paths/result_path_adj_lst_top_3_20240103_081822.json\"\n",
    "path_file = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/traversal_paths/result_path_adj_lst_top_5_20240103_082740.json\"\n",
    "paths = json.load(open(path_file, \"r\"))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# analyze the in-degree of the nodes in the adjacency list\n",
    "in_degree = defaultdict(int)\n",
    "for query_id, neighbors in tqdm.tqdm(adj_lst.items()):\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor[0] not in in_degree:\n",
    "            in_degree[neighbor[0]] = 0\n",
    "        in_degree[neighbor[0]] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flattened_path = [item for sublist in paths for item in sublist]\n",
    "assert len(flattened_path) == 890000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(flattened_path.index('10_1832'))\n",
    "print(flattened_path.index('87_1340'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print the sample paths\n",
    "start_idx = 23998\n",
    "for path in paths[start_idx:start_idx+10]:\n",
    "    print(path, adj_lst[path[0]], in_degree[path[0]], len(adj_lst[path[0]]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the distribution of the path lengths\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(path_lengths, bins=100)\n",
    "plt.title(\"Distribution of the path lengths\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synpre_env",
   "language": "python",
   "display_name": "synpre_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
