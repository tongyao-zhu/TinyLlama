{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "doc_ids = ['doc0', 'doc1', 'doc3', 'doc5', 'doc7', 'doc9']\n",
    "for doc_id in doc_ids:\n",
    "    graph.add_node(Node(doc_id))\n",
    "edges = {\n",
    "    ('doc0', 'doc9'): 0.8,\n",
    "    ('doc1', 'doc3'): 0.7,\n",
    "    ('doc7', 'doc3'): 0.2,\n",
    "    ('doc5', 'doc7'): 0.9,\n",
    "    ('doc5', 'doc3'): 0.6,\n",
    "}\n",
    "for edge in edges:\n",
    "    graph.add_edge(graph.get_node(edge[0]), graph.get_node(edge[1]), edges[edge], directed=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_path = max_tsp_traverse(graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Result path:\", [node.get_doc_id() for node in result_path])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "read the saved search results (in TREC format)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage:\n",
    "file_path = '/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/bm25_search_results/chunk_88.result.txt'\n",
    "result_dict = read_trec_results(file_path)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(result_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read result from all chunks\n",
    "result_dict = {}\n",
    "for i in tqdm.tqdm(list(range(0, 89)) + ['search_fail_queries_added']):\n",
    "    file_path = '/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/bm25_search_results/chunk_{i}.result.txt'.format(i=i)\n",
    "    result_dict.update(read_trec_results(file_path))\n",
    "\n",
    "print(\"Total number of queries:\", len(result_dict))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# count how many docs have itself as the top1 neighbor\n",
    "count = 0\n",
    "# length counts\n",
    "lengths = []\n",
    "for query_id, docs in result_dict.items():\n",
    "    lengths.append(len(docs))\n",
    "    if docs[0]['doc_id'] == query_id:\n",
    "        count += 1\n",
    "print(\"Number of queries that have itself as the top1 neighbor:\", count, \"percentage:\", count/len(result_dict))\n",
    "print(\"Average number of neighbors:\", np.mean(lengths))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "directory_path = '/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/train/'\n",
    "all_file_ids = get_file_ids(directory_path)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Total number of files: {len(all_file_ids)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sequence_set = set()\n",
    "for i in range(0, 89):\n",
    "    for j in range(0, 10000):\n",
    "        sequence_set.add(\"{i}_{j}\".format(i=i, j=j))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ensure that the two sets are equal\n",
    "len(sequence_set - set(all_file_ids))\n",
    "len(set(all_file_ids) - sequence_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "not_searched_query_ids = list()\n",
    "for query_id in sequence_set:\n",
    "    if query_id not in result_dict:\n",
    "        not_searched_query_ids.append(query_id)\n",
    "print(\"Number of queries not searched:\", len(not_searched_query_ids))\n",
    "print(\"Example query IDs:\", not_searched_query_ids[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "to_write_data = []\n",
    "not_searched_query_ids = sorted(not_searched_query_ids)\n",
    "for docid in tqdm.tqdm(not_searched_query_ids, total=len(not_searched_query_ids)):\n",
    "    chunk_id, seq_id = docid.split(\"_\")\n",
    "    base_path = \"/home/aiops/zhuty/ret_pretraining_data/redpajama_2b_id_added/queries\"\n",
    "    jsonl_file = os.path.join(base_path, \"chunk_{}.jsonl\".format(chunk_id))\n",
    "    with open(jsonl_file, \"r\") as f:\n",
    "        # directly go the line\n",
    "        line = f.readlines()[int(seq_id)]\n",
    "        data = json.loads(line)\n",
    "        assert data[\"id\"] == docid\n",
    "        if len(data['title']) > 2000:\n",
    "            print(\"problematic docid\", docid)\n",
    "            print(data['title'])\n",
    "            print(len(data['title'].split()))\n",
    "            continue\n",
    "        to_write_data.append(data)\n",
    "\n",
    "        # a slower version\n",
    "        # for line in f:\n",
    "        #     line = line.strip()\n",
    "        #     if line:\n",
    "        #         data = json.loads(line)\n",
    "        #         if data[\"id\"] == docid:\n",
    "        #             # print(data)\n",
    "        #             # print(len(data['title'].split()))\n",
    "        #             to_write_data.append(data)\n",
    "        #             break\n",
    "# write to jsonl\n",
    "with open(os.path.join(base_path, \"chunk_search_fail_queries_added.jsonl\"), \"w\") as f:\n",
    "    for data in to_write_data:\n",
    "        f.write(json.dumps(data) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# how to import?\n",
    "import sys\n",
    "sys.path.append('/home/aiops/zhuty/tinyllama/processing/graphs')\n",
    "\n",
    "from graph import Graph, Node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"len of all_file_ids\", len(all_file_ids))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Add the documents as nodes\n",
    "graph = Graph()\n",
    "for doc_id in all_file_ids:\n",
    "    graph.add_node(Node(doc_id))\n",
    "\n",
    "print(\"Number of nodes:\", graph.get_node_count())\n",
    "# add the top_k neighbors as edges\n",
    "top_k = 5\n",
    "for query_id, docs in tqdm.tqdm(result_dict.items()):\n",
    "    for doc in docs[:top_k+1]:\n",
    "        if doc['doc_id'] == query_id:\n",
    "            # neighbor is the query itself\n",
    "            continue\n",
    "        graph.add_edge(graph.get_node(query_id), graph.get_node(doc['doc_id']), doc['score'], directed=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_dict['2_1578']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# traverse the graph\n",
    "result_path = max_tsp_traverse(graph)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.get_node_neighbors('2_1578')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph.get_node_count()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_path = [node.get_doc_id() for node in result_path]\n",
    "print(\"Result path:\", result_path[:10])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"hellow\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "commands = []\n",
    "for i in range(0, 89):\n",
    "    commands.append((\"head -n 10000 redpajama_20b_id_added/train/chunk_{i}.jsonl > redpajama_2b_id_added/train/chunk_{i}.jsonl\".format(i=i)))\n",
    "print(\";\".join(commands))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_cpus = 5\n",
    "filenames = range(0, 23)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array_split(filenames, num_cpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synpre_env",
   "language": "python",
   "display_name": "synpre_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
