,results,group_subtasks,configs,versions,n-shot,config,git_hash,pretty_env_info,transformers_version,upper_git_hash,eval_loss_arxiv,eval_loss_book,eval_loss_cc,eval_loss_rpwiki_en,name,ds
0,"{'lambada_openai': {'perplexity,none': 37.484991855775846, 'perplexity_stderr,none': 1.4854332510046337, 'acc,none': 0.3013778381525325, 'acc_stderr,none': 0.006392767482978506, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3132842063333997, 'acc_stderr,none': 0.00462880925848352, 'acc_norm,none': 0.3611830312686716, 'acc_norm_stderr,none': 0.004793617835645098, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-160000-ckpt-step-20000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-166-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Byte Order:                         Little Endian
Address sizes:                      43 bits physical, 48 bits virtual
CPU(s):                             256
On-line CPU(s) list:                0-255
Thread(s) per core:                 2
Core(s) per socket:                 64
Socket(s):                          2
NUMA node(s):                       8
Vendor ID:                          AuthenticAMD
CPU family:                         23
Model:                              49
Model name:                         AMD EPYC 7742 64-Core Processor
Stepping:                           0
Frequency boost:                    enabled
CPU MHz:                            3385.435
CPU max MHz:                        2250.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           4491.71
Virtualization:                     AMD-V
L1d cache:                          4 MiB
L1i cache:                          4 MiB
L2 cache:                           64 MiB
L3 cache:                           512 MiB
NUMA node0 CPU(s):                  0-15,128-143
NUMA node1 CPU(s):                  16-31,144-159
NUMA node2 CPU(s):                  32-47,160-175
NUMA node3 CPU(s):                  48-63,176-191
NUMA node4 CPU(s):                  64-79,192-207
NUMA node5 CPU(s):                  80-95,208-223
NUMA node6 CPU(s):                  96-111,224-239
NUMA node7 CPU(s):                  112-127,240-255
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Vulnerable
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca sme sev sev_es

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.3542044162750244,2.5998191833496094,2.308654546737671,2.478827714920044,1b_cc_8k_iter-160000-ckpt-step-20000,cc_8k
1,"{'lambada_openai': {'perplexity,none': 35.828988640657286, 'perplexity_stderr,none': 1.388353504988054, 'acc,none': 0.3120512322918688, 'acc_stderr,none': 0.006455101452842902, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3210515833499303, 'acc_stderr,none': 0.004659263952756618, 'acc_norm,none': 0.3767177853017327, 'acc_norm_stderr,none': 0.004835728903731382, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-200000-ckpt-step-25000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-166-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Byte Order:                         Little Endian
Address sizes:                      43 bits physical, 48 bits virtual
CPU(s):                             256
On-line CPU(s) list:                0-255
Thread(s) per core:                 2
Core(s) per socket:                 64
Socket(s):                          2
NUMA node(s):                       8
Vendor ID:                          AuthenticAMD
CPU family:                         23
Model:                              49
Model name:                         AMD EPYC 7742 64-Core Processor
Stepping:                           0
Frequency boost:                    enabled
CPU MHz:                            2588.484
CPU max MHz:                        2250.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           4491.71
Virtualization:                     AMD-V
L1d cache:                          4 MiB
L1i cache:                          4 MiB
L2 cache:                           64 MiB
L3 cache:                           512 MiB
NUMA node0 CPU(s):                  0-15,128-143
NUMA node1 CPU(s):                  16-31,144-159
NUMA node2 CPU(s):                  32-47,160-175
NUMA node3 CPU(s):                  48-63,176-191
NUMA node4 CPU(s):                  64-79,192-207
NUMA node5 CPU(s):                  80-95,208-223
NUMA node6 CPU(s):                  96-111,224-239
NUMA node7 CPU(s):                  112-127,240-255
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Vulnerable
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca sme sev sev_es

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.3049299716949463,2.5517325401306152,2.2717719078063965,2.436030864715576,1b_cc_8k_iter-200000-ckpt-step-25000,cc_8k
2,"{'lambada_openai': {'perplexity,none': 30.63989000991296, 'perplexity_stderr,none': 1.1693895603247821, 'acc,none': 0.32815835435668544, 'acc_stderr,none': 0.006541649423371711, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3271260705038837, 'acc_stderr,none': 0.004682048906622325, 'acc_norm,none': 0.38279227245568614, 'acc_norm_stderr,none': 0.0048507486878599446, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-240000-ckpt-step-30000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-166-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Byte Order:                         Little Endian
Address sizes:                      43 bits physical, 48 bits virtual
CPU(s):                             256
On-line CPU(s) list:                0-255
Thread(s) per core:                 2
Core(s) per socket:                 64
Socket(s):                          2
NUMA node(s):                       8
Vendor ID:                          AuthenticAMD
CPU family:                         23
Model:                              49
Model name:                         AMD EPYC 7742 64-Core Processor
Stepping:                           0
Frequency boost:                    enabled
CPU MHz:                            3368.179
CPU max MHz:                        2250.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           4491.71
Virtualization:                     AMD-V
L1d cache:                          4 MiB
L1i cache:                          4 MiB
L2 cache:                           64 MiB
L3 cache:                           512 MiB
NUMA node0 CPU(s):                  0-15,128-143
NUMA node1 CPU(s):                  16-31,144-159
NUMA node2 CPU(s):                  32-47,160-175
NUMA node3 CPU(s):                  48-63,176-191
NUMA node4 CPU(s):                  64-79,192-207
NUMA node5 CPU(s):                  80-95,208-223
NUMA node6 CPU(s):                  96-111,224-239
NUMA node7 CPU(s):                  112-127,240-255
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Vulnerable
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca sme sev sev_es

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.249361276626587,2.514803886413574,2.239223003387451,2.4119997024536133,1b_cc_8k_iter-240000-ckpt-step-30000,cc_8k
3,"{'lambada_openai': {'perplexity,none': 30.931951716283, 'perplexity_stderr,none': 1.1685414865866257, 'acc,none': 0.32699398408693964, 'acc_stderr,none': 0.006535689740487126, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3337980481975702, 'acc_stderr,none': 0.0047060481167649154, 'acc_norm,none': 0.39543915554670384, 'acc_norm_stderr,none': 0.004879455474663794, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-300000-ckpt-step-37500_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3092.004
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.1844937801361084,2.4784231185913086,2.2012505531311035,2.392225503921509,1b_cc_8k_iter-300000-ckpt-step-37500,cc_8k
4,"{'lambada_openai': {'perplexity,none': 43.71539212450929, 'perplexity_stderr,none': 1.8098796113019482, 'acc,none': 0.28856976518532895, 'acc_stderr,none': 0.006312532759373336, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.31975702051384186, 'acc_stderr,none': 0.0046542916612558926, 'acc_norm,none': 0.3695478988249353, 'acc_norm_stderr,none': 0.004816958817726063, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v1_8k/iter-160000-ckpt-step-20000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3094.986
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.356217622756958,2.6067004203796387,2.2981834411621094,2.466277837753296,1b_cc_merged_v1_8k_iter-160000-ckpt-step-20000,cc_merged_v1_8k
5,"{'lambada_openai': {'perplexity,none': 36.390555156984675, 'perplexity_stderr,none': 1.4462842775902272, 'acc,none': 0.3087521831942558, 'acc_stderr,none': 0.006436265900629435, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.32772356104361683, 'acc_stderr,none': 0.004684241685200294, 'acc_norm,none': 0.38090021907986454, 'acc_norm_stderr,none': 0.004846156699486673, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v1_8k/iter-200000-ckpt-step-25000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3063.776
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.3093032836914062,2.5632553100585938,2.2590596675872803,2.428699254989624,1b_cc_merged_v1_8k_iter-200000-ckpt-step-25000,cc_merged_v1_8k
6,"{'lambada_openai': {'perplexity,none': 32.39430698216291, 'perplexity_stderr,none': 1.2546429483081267, 'acc,none': 0.3271880457985639, 'acc_stderr,none': 0.006536686193974629, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3309101772555268, 'acc_stderr,none': 0.004695791340502876, 'acc_norm,none': 0.38946425014937264, 'acc_norm_stderr,none': 0.0048663222583359665, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v1_8k/iter-240000-ckpt-step-30000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3066.983
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.269057512283325,2.5217082500457764,2.224637508392334,2.403008460998535,1b_cc_merged_v1_8k_iter-240000-ckpt-step-30000,cc_merged_v1_8k
7,"{'lambada_openai': {'perplexity,none': 27.256736130373255, 'perplexity_stderr,none': 1.0238826744432699, 'acc,none': 0.3512516980399767, 'acc_stderr,none': 0.006650578225573469, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3376817367058355, 'acc_stderr,none': 0.004719529099913147, 'acc_norm,none': 0.4078868751244772, 'acc_norm_stderr,none': 0.004904375631128878, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v1_8k/iter-300000-ckpt-step-37500_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3039.738
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.168349027633667,2.481196641921997,2.184861898422241,2.366791248321533,1b_cc_merged_v1_8k_iter-300000-ckpt-step-37500,cc_merged_v1_8k
8,"{'lambada_openai': {'perplexity,none': 31.38859765622101, 'perplexity_stderr,none': 1.2540747667185848, 'acc,none': 0.3405783039006404, 'acc_stderr,none': 0.006602405259021262, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.31846245767775344, 'acc_stderr,none': 0.004649278153073844, 'acc_norm,none': 0.3647679745070703, 'acc_norm_stderr,none': 0.004803812631994931, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v2_8k/iter-160000-ckpt-step-20000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3068.809
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.4101600646972656,2.578890085220337,2.3217580318450928,2.45318865776062,1b_cc_merged_v2_8k_iter-160000-ckpt-step-20000,cc_merged_v2_8k
9,"{'lambada_openai': {'perplexity,none': 33.885559155804046, 'perplexity_stderr,none': 1.3590630677706959, 'acc,none': 0.3293227246264312, 'acc_stderr,none': 0.006547563491030402, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3211511651065525, 'acc_stderr,none': 0.004659644733309563, 'acc_norm,none': 0.37821151165106554, 'acc_norm_stderr,none': 0.0048394970205366235, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v2_8k/iter-200000-ckpt-step-25000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         2888.364
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.349155902862549,2.5516607761383057,2.2867138385772705,2.4309866428375244,1b_cc_merged_v2_8k_iter-200000-ckpt-step-25000,cc_merged_v2_8k
10,"{'lambada_openai': {'perplexity,none': 35.33596925780864, 'perplexity_stderr,none': 1.3720286669640682, 'acc,none': 0.3126334174267417, 'acc_stderr,none': 0.006458385716767267, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.32901812387970525, 'acc_stderr,none': 0.0046889631757581415, 'acc_norm,none': 0.38697470623381797, 'acc_norm_stderr,none': 0.004860623733461118, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v2_8k/iter-240000-ckpt-step-30000_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-88-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              2
Core(s) per socket:              24
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      23
Model:                           49
Model name:                      AMD EPYC 7352 24-Core Processor
Stepping:                        0
CPU MHz:                         3066.960
BogoMIPS:                        4591.49
Virtualization:                  AMD-V
L1d cache:                       1.5 MiB
L1i cache:                       1.5 MiB
L2 cache:                        24 MiB
L3 cache:                        256 MiB
NUMA node0 CPU(s):               0-5,48-53
NUMA node1 CPU(s):               6-11,54-59
NUMA node2 CPU(s):               12-17,60-65
NUMA node3 CPU(s):               18-23,66-71
NUMA node4 CPU(s):               24-29,72-77
NUMA node5 CPU(s):               30-35,78-83
NUMA node6 CPU(s):               36-41,84-89
NUMA node7 CPU(s):               42-47,90-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Full AMD retpoline, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.356177806854248,2.518897533416748,2.264925718307495,2.4192278385162354,1b_cc_merged_v2_8k_iter-240000-ckpt-step-30000,cc_merged_v2_8k
11,"{'lambada_openai': {'perplexity,none': 27.470935147560528, 'perplexity_stderr,none': 1.0435144103317135, 'acc,none': 0.3526101300213468, 'acc_stderr,none': 0.006656446028047874, 'alias': 'lambada_openai'}, 'hellaswag': {'acc,none': 0.3329018123879705, 'acc_stderr,none': 0.004702886273189427, 'acc_norm,none': 0.3973312089225254, 'acc_norm_stderr,none': 0.004883455188908959, 'alias': 'hellaswag'}}","{'hellaswag': [], 'lambada_openai': []}","{'hellaswag': {'task': 'hellaswag', 'group': ['multiple_choice'], 'dataset_path': 'hellaswag', 'training_split': 'train', 'validation_split': 'validation', 'process_docs': 'def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[""ctx_a""] + "" "" + doc[""ctx_b""].capitalize()\n        out_doc = {\n            ""query"": preprocess(doc[""activity_label""] + "": "" + ctx),\n            ""choices"": [preprocess(ending) for ending in doc[""endings""]],\n            ""gold"": int(doc[""label""]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n', 'doc_to_text': '{{query}}', 'doc_to_target': '{{label}}', 'doc_to_choice': 'choices', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'acc_norm', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'multiple_choice', 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 1.0}}, 'lambada_openai': {'task': 'lambada_openai', 'group': ['lambada'], 'dataset_path': 'EleutherAI/lambada_openai', 'dataset_name': 'default', 'test_split': 'test', 'doc_to_text': ""{{text.split(' ')[:-1]|join(' ')}}"", 'doc_to_target': ""{{' '+text.split(' ')[-1]}}"", 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 10, 'metric_list': [{'metric': 'perplexity', 'aggregation': 'perplexity', 'higher_is_better': False}, {'metric': 'acc', 'aggregation': 'mean', 'higher_is_better': True}], 'output_type': 'loglikelihood', 'repeats': 1, 'should_decontaminate': True, 'doc_to_decontamination_query': '{{text}}', 'metadata': {'version': 1.0}}}","{'hellaswag': 1.0, 'lambada_openai': 1.0}","{'hellaswag': 10, 'lambada_openai': 10}","{'model': 'hf', 'model_args': 'pretrained=/home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_merged_v2_8k/iter-300000-ckpt-step-37500_hf,dtype=float,tokenizer=meta-llama/Llama-2-7b-hf', 'batch_size': '4', 'batch_sizes': [], 'device': 'cuda:0', 'use_cache': None, 'limit': None, 'bootstrap_iters': 100000, 'gen_kwargs': None}",,"PyTorch version: 2.1.0+cu121
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
Clang version: Could not collect
CMake version: version 3.26.4
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.4.0-166-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 11.8.89
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: GPU 0: NVIDIA A100-SXM4-40GB
Nvidia driver version: 535.129.03
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                       x86_64
CPU op-mode(s):                     32-bit, 64-bit
Byte Order:                         Little Endian
Address sizes:                      43 bits physical, 48 bits virtual
CPU(s):                             256
On-line CPU(s) list:                0-255
Thread(s) per core:                 2
Core(s) per socket:                 64
Socket(s):                          2
NUMA node(s):                       8
Vendor ID:                          AuthenticAMD
CPU family:                         23
Model:                              49
Model name:                         AMD EPYC 7742 64-Core Processor
Stepping:                           0
Frequency boost:                    enabled
CPU MHz:                            2928.014
CPU max MHz:                        2250.0000
CPU min MHz:                        1500.0000
BogoMIPS:                           4491.36
Virtualization:                     AMD-V
L1d cache:                          4 MiB
L1i cache:                          4 MiB
L2 cache:                           64 MiB
L3 cache:                           512 MiB
NUMA node0 CPU(s):                  0-15,128-143
NUMA node1 CPU(s):                  16-31,144-159
NUMA node2 CPU(s):                  32-47,160-175
NUMA node3 CPU(s):                  48-63,176-191
NUMA node4 CPU(s):                  64-79,192-207
NUMA node5 CPU(s):                  80-95,208-223
NUMA node6 CPU(s):                  96-111,224-239
NUMA node7 CPU(s):                  112-127,240-255
Vulnerability Gather data sampling: Not affected
Vulnerability Itlb multihit:        Not affected
Vulnerability L1tf:                 Not affected
Vulnerability Mds:                  Not affected
Vulnerability Meltdown:             Not affected
Vulnerability Mmio stale data:      Not affected
Vulnerability Retbleed:             Vulnerable
Vulnerability Spec store bypass:    Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:           Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:           Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:                Not affected
Vulnerability Tsx async abort:      Not affected
Flags:                              fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr wbnoinvd arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif umip rdpid overflow_recov succor smca sme sev sev_es

Versions of relevant libraries:
[pip3] numpy==1.22.4
[pip3] pytorch-lightning==2.1.3
[pip3] torch==2.1.0
[pip3] torchmetrics==1.3.0.post0
[pip3] triton==2.1.0
[conda] mkl                       2024.0.0                 pypi_0    pypi
[conda] mkl-fft                   1.3.1                    pypi_0    pypi
[conda] mkl-service               2.4.0                    pypi_0    pypi
[conda] numpy                     1.22.4                   pypi_0    pypi
[conda] pytorch-lightning         2.1.3                    pypi_0    pypi
[conda] torch                     2.1.0                    pypi_0    pypi
[conda] torchmetrics              1.3.0.post0              pypi_0    pypi
[conda] triton                    2.1.0                    pypi_0    pypi",4.34.0,,2.221771478652954,2.5028908252716064,2.236948251724243,2.390986919403076,1b_cc_merged_v2_8k_iter-300000-ckpt-step-37500,cc_merged_v2_8k
