{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### This notebook analyzes the output of the few-shot evaluation\n",
    "i.e. whether it follows the format of the few-shot evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def remove_underline(x):\n",
    "    return x.replace(\"_\", \"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# read the output logs file\n",
    "with open('/home/aiops/zhuty/tinyllama/scripts/fewshot_eval/outputs/logs', 'r') as file:\n",
    "    data = file.readlines()\n",
    "data = [ json.loads(x) for x in data]\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n",
      "Existing\n"
     ]
    }
   ],
   "source": [
    "# BASE_PATH = '/home/aiops/zhuty/tinyllama/scripts//fewshot_eval/fewshot_out_mar27'\n",
    "BASE_PATH = '/home/aiops/zhuty/tinyllama/scripts/fewshot_eval/outputs'\n",
    "commands = []\n",
    "data = []\n",
    "\n",
    "NSHOTS=24\n",
    "shot_num = NSHOTS\n",
    "# iter_name = \"iter-380000-ckpt-step-47500_hf\"\n",
    "# size=\"1b\"\n",
    "\n",
    "high_priority=False\n",
    "# iter_name = \"iter-160000-ckpt-step-40000_hf\"\n",
    "# size=\"360M\"\n",
    "# iter_name = \"iter-240000-ckpt-step-60000_hf\"\n",
    "# size=\"120M\"\n",
    "iter_name = \"iter-380000-ckpt-step-47500_hf\"\n",
    "size=\"1b\"\n",
    "\n",
    "\n",
    "\n",
    "TASK_CLASS=\"icl\"\n",
    "\n",
    "class_to_tasks_mapping = {\"icl\": ['agnews' ,'amazon' ,'dbpedia' ,'sst2' ,'tweet_hate' ,'tweet_offensive' ,'yelp' ],\n",
    "                          \"obqa\": [ \"squad\", \"nq_obqa\", \"tq_obqa\" ,\"hotpotqa\"],\n",
    "                          \"cbqa\": [\"tq\", \"nq\"]\n",
    "                          }\n",
    "\n",
    "class_to_seed_mapping = {\"icl\": range(42, 58),\n",
    "                         \"obqa\": range(42, 46+1),\n",
    "                         \"cbqa\": range(42, 46 + 1)\n",
    "                         }\n",
    "all_data = {}\n",
    "for task_name in  class_to_tasks_mapping[TASK_CLASS]:\n",
    "    for model_name in ['cc', 'cc_merged_v1', 'cc_merged_v2' ,'cc_merged_v3']:\n",
    "        for seed_num in class_to_seed_mapping[TASK_CLASS]:\n",
    "            full_name = f\"tiny_LLaMA_{size}_8k_{model_name}_8k-{iter_name}\"\n",
    "            # full_name = \"TinyLlama/TinyLlama-1.1B-step-50K-105b\"\n",
    "            result_path = os.path.join(BASE_PATH,full_name, f'{task_name}_{shot_num}_{seed_num}_prompts_and_preds.json')\n",
    "            if not os.path.exists(result_path):\n",
    "                print(f\"File {result_path} does not exist\")\n",
    "                commands.append(f\"python /home/aiops/zhuty/tinyllama/scripts/fewshot_eval/eval.py --model_name {full_name} --task_name {task_name} --n_shot {shot_num} --seed {seed_num} --high_priority {high_priority}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Existing\")\n",
    "                curr_data = json.load(open(result_path, 'r'))\n",
    "                all_data[(task_name, model_name, seed_num)] = curr_data\n",
    "                # curr_prompts = [x['prompt'] for x in curr_data['prompts']]\n",
    "                # curr_preds = [x['pred'] for x in curr_data['preds']]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data[(('amazon', 'cc', 52))]['preds']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def is_generated_label(output_string, labels):\n",
    "    gen_label = output_string.split(\"\\n\")[0]\n",
    "    if gen_label in labels:\n",
    "        return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# task_to_labels = {\"agnews\": {0: \"world\", 1: \"sports\", 2: \"business\", 3: \"science\"},\n",
    "# \"amazon\": {0: \"negative\", 1: \"positive\"},\n",
    "# \"yelp\": {0: \"negative\", 1: \"positive\"},\n",
    "# \"sst2\": {0: \"positive\", 1: \"negative\"},\n",
    "# \"tweet_hate\": {0: \"Non-hate\", 1: \"Hate\"},\n",
    "# \"tweet_offensive\":  {0: \"Non-hate\", 1: \"Hate\"},\n",
    "#                   }\n",
    "#\n",
    "# task_to_labels['dbpedia'] = {idx:name for idx,name in enumerate([\"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\", \"MeanOfTransportation\",\n",
    "#              \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\", \"Album\", \"Film\", \"WrittenWork\", ])}\n",
    "\n",
    "task_to_labels = {\"agnews\": {0: \"M\", 1: \"N\", 2: \"Q\", 3: \"P\"},\n",
    "\"amazon\": {0: \"foo\", 1: \"bar\"},\n",
    "\"yelp\": {0: \"foo\", 1: \"bar\"},\n",
    "\"sst2\": {0: \"foo\", 1: \"bar\"},\n",
    "\"tweet_hate\": {0: \"foo\", 1: \"bar\"},\n",
    "\"tweet_offensive\":  {0: \"foo\", 1: \"bar\"},\n",
    "                  }\n",
    "\n",
    "task_to_labels['dbpedia'] = {idx:name for idx,name in enumerate( [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\"])}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_data[(('tweet_offensive', 'cc_merged_v3', 52))]['prompts'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_model_percentage = {}\n",
    "task_model_wrong_cases = {}\n",
    "# take the average over all the seeds\n",
    "for key, data in all_data.items():\n",
    "    # data = all_data[(('tweet_offensive', 'cc', 52))]['preds']\n",
    "    task_name, model_name, seed_num = key\n",
    "    labels = task_to_labels[task_name].values()\n",
    "    data = data['preds']\n",
    "\n",
    "    for x in data:\n",
    "        if (task_name, model_name) not in task_model_percentage:\n",
    "                task_model_percentage[(task_name, model_name)] = []\n",
    "        if (task_name, model_name) not in task_model_wrong_cases:\n",
    "            task_model_wrong_cases[(task_name, model_name)] = []\n",
    "        if is_generated_label(x, labels):\n",
    "            task_model_percentage[(task_name, model_name)].append(1)\n",
    "        else:\n",
    "            task_model_wrong_cases[(task_name, model_name)].append(x)\n",
    "            task_model_percentage[(task_name, model_name)].append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print the average of correct labels\n",
    "for key, data in task_model_percentage.items():\n",
    "    print(key, np.mean(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(task_model_wrong_cases[('tweet_offensive', 'cc_merged_v3')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "assert len(commands) == 0 , \"missing commands {}\".format( len(commands))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def extract_step(x):\n",
    "    # strip the _hf\n",
    "    x = x[:-3]\n",
    "    return int(x.split('-')[-1])\n",
    "\n",
    "def extract_model_name(x):\n",
    "    \"\"\"\n",
    "    Sample input: /home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-200000-ckpt-step-25000_hf\n",
    "    Sample output: tiny_LLaMA_1b_8k\n",
    "    Args:\n",
    "        x:\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if '/home/aiops/zhuty' in x:\n",
    "        folder_name = x.split('/')[-2] # tiny_LLaMA_1b_8k_cc_8k\n",
    "        return (\"_\").join(folder_name.split('_')[:4]) # tiny_LLaMA_1b_8k\n",
    "    else:\n",
    "        # sample model name: tyzhu/tiny_LLaMA_120M_8k_cc_8k_iter-240000-ckpt-step-60000_hf\n",
    "        return x.strip(\"tyzhu/\").split(\"_cc\")[0]\n",
    "\n",
    "def extract_pretrain_dataset(x):\n",
    "    \"\"\"\n",
    "    Sample input: /home/aiops/zhuty/tinyllama/out/tiny_LLaMA_1b_8k_cc_8k/iter-200000-ckpt-step-25000_hf\n",
    "    Sample output: cc_8k\n",
    "    Args:\n",
    "        x:\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    if '/home/aiops/zhuty' in x:\n",
    "        folder_name = x.split('/')[-2] # tiny_LLaMA_1b_8k_cc_8k\n",
    "        return (\"_\").join(folder_name.split('_')[4:]) # cc_8k\n",
    "    else:\n",
    "        # sample model name: tyzhu/tiny_LLaMA_120M_8k_cc_8k_iter-240000-ckpt-step-60000_hf\n",
    "        return x.strip(\"tyzhu/\").split(\"_8k_\")[1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synpre_env",
   "language": "python",
   "display_name": "synpre_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
