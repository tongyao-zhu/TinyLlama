{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def remove_underline(x):\n",
    "    return x.replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_to_label_spaces = {'amazon': ['positive', 'negative'], 'sst2': ['positive', 'negative'], 'yelp': ['positive', 'negative'],\n",
    "                        'tweet_hate': ['Hate', 'Non-hate',], 'tweet_offensive': ['Hate', 'Non-hate'],\n",
    "                        'agnews': {'world', 'science', 'sports', 'business'},\n",
    "                        'dbpedia': {\"Company\", \"EducationalInstitution\", \"Artist\", \"Athlete\", \"OfficeHolder\",\n",
    "                                    \"MeanOfTransportation\", \"Building\", \"NaturalPlace\", \"Village\", \"Animal\", \"Plant\",\n",
    "                                    \"Album\", \"Film\", \"WrittenWork\"}\n",
    "                        }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalise_pred(pred):\n",
    "    return pred.strip().split(\"\\n\")[0].strip()\n",
    "\n",
    "def check_file_in_label_rate(pred_data, task):\n",
    "    assert len(pred_data['prompts']) == len(pred_data['preds'])\n",
    "    invalid_labels = [x for x in pred_data['preds'] if normalise_pred(x) not in task_to_label_spaces[task]]\n",
    "    return 1 - len(invalid_labels) / len(pred_data['preds']), invalid_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/aiops/zhuty/tinyllama/scripts/fewshot_eval/outputs/'\n",
    "commands = []\n",
    "data = []\n",
    "\n",
    "\n",
    "high_priority=False\n",
    "\n",
    "# size=\"360M\"\n",
    "# iter_name = \"iter-160000-ckpt-step-40000_hf\"\n",
    "#iter_name = \"iter-110000-ckpt-step-27500_hf\"\n",
    "# iter_name = \"iter-260000-ckpt-step-65000_hf\"\n",
    "\n",
    "size=\"1b\"\n",
    "# iter_name = \"iter-480000-ckpt-step-60000_hf\"\n",
    "# iter_name = \"iter-380000-ckpt-step-47500_hf\"\n",
    "iter_name = \"iter-600000-ckpt-step-75000_hf\"\n",
    "# model_names = ['cc_merged_v2_8k', 'intramask_cc_8k', 'cc_merged_v2_8k_intracccont','cc_8k', 'cc_merged_v1_8k', 'adamask_cc_merged_v2_8k', ] # 'intramask_cc_merged_v2_8k']\n",
    "# model_names = ['cc_merged_v2_8k', 'intramask_cc_8k', 'cc_merged_v2_8k_intracccont','cc_8k',   'adamask_cc_merged_v2_8k', 'intramask_cc_merged_v2_8k']\n",
    "# model_names = ['intramask_cc_8k', 'intramask_cc_merged_v2_8k', 'cc_merged_v2_8k_intrav2cont','cc_8k', 'adamask_cc_merged_v2_8k',  'cc_merged_v2_8k',]\n",
    "# model_names = ['cc_merged_v2_8k', 'intramask_cc_8k', 'cc_merged_v2_8k_intracccont','cc_8k', 'cc_merged_v1_8k', 'adamask_cc_merged_v2_8k', ] # 'intramask_cc_merged_v2_8k']\n",
    "\n",
    "model_names= ['BM25Chunk', \"UniChunk\", \"MixChunk\", \"IntraDoc\"]\n",
    "# model_names = ['cc_merged_v2_8k', 'intramask_cc_8k', 'cc_merged_v1_8k', 'adamask_cc_merged_v2_8k', 'cc_merged_v2_8k_intracccont','cc_8k',]\n",
    "# model_names = ['baseline']\n",
    "\n",
    "\n",
    "# TASK_CLASS, shot_nums, rag_num_docs_lst =\"obqa\", [8, 16], [\"\"]\n",
    "# TASK_CLASS, shot_nums, rag_num_docs_lst =\"obqa\", [4], [\"\"]\n",
    "TASK_CLASS, shot_nums, rag_num_docs_lst =\"icl\", [24,48], [\"\"]\n",
    "# TASK_CLASS, shot_nums, rag_num_docs_lst =\"cbqa\", [12,24], [\"\"]\n",
    "# TASK_CLASS, shot_nums, rag_num_docs_lst =\"obqa_rag\", [3], [1,3,5,10]\n",
    "\n",
    "\n",
    "class_to_tasks_mapping = {\"icl\": ['agnews' ,'amazon' ,'dbpedia' ,'sst2','tweet_hate' ,'tweet_offensive' ,'yelp' ],\n",
    "                          \"obqa\": [ \"squad\",\"hotpotqa\"],\n",
    "                          \"obqa_rag\": [\"nq_obqa\", \"tq_obqa\"],\n",
    "                          \"cbqa\": [\"tq\", \"nq\"],\n",
    "                          }\n",
    "\n",
    "class_to_seed_mapping = {\"icl\": range(42, 58),\n",
    "                         \"obqa\": range(42, 46+1),\n",
    "                         \"cbqa\": range(42, 46 + 1),\n",
    "                            \"obqa_rag\": range(42, 46 + 1),\n",
    "                         }\n",
    "for task_name in  class_to_tasks_mapping[TASK_CLASS]:\n",
    "    for shot_num in shot_nums:\n",
    "        for rag_num_docs in rag_num_docs_lst:\n",
    "            if task_name == \"yelp\" and shot_num == 48:\n",
    "               continue\n",
    "            for model_name in model_names:\n",
    "                # if '8k' not in model_name:\n",
    "                #     model_name = f\"{model_name}_8k\"\n",
    "                for seed_num in class_to_seed_mapping[TASK_CLASS]:\n",
    "                    # full_name = f\"tiny_LLaMA_{size}_8k_{model_name}-{iter_name}\"\n",
    "                    full_name = model_name\n",
    "                    # full_name = \"TinyLlama-1.1B-step-50K-105b\"\n",
    "                    if TASK_CLASS == \"obqa_rag\":\n",
    "                        result_path = os.path.join(BASE_PATH,full_name, f'{task_name}_{shot_num}_{seed_num}_{rag_num_docs}.json')\n",
    "                    else:\n",
    "                        result_path = os.path.join(BASE_PATH,full_name, f'{task_name}_{shot_num}_{seed_num}.json')\n",
    "                    if not os.path.exists(result_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        # print(\"Existing\", result_path)\n",
    "                        acc_result = json.load(open(result_path, 'r'))\n",
    "                        pred_path = result_path.replace(\".json\", '_prompts_and_preds.json')\n",
    "                        pred_result = json.load(open(pred_path, 'r'))\n",
    "                        acc_result['valid_ratio'], invalid_preds = check_file_in_label_rate(pred_result, task_name)\n",
    "                        # assert (acc_result['valid_ratio'] > 0.9) or task_name in ['dbpedia', 'agnews'] , f\"valid_ratio is {acc_result['valid_ratio']}\"\n",
    "                        if acc_result['valid_ratio'] < 0.9:\n",
    "                            if task_name not in ['dbpedia', 'agnews']:\n",
    "                                print(\"Task\", task_name, \"Sample invalid preds\", invalid_preds[:10])\n",
    "                        if TASK_CLASS == \"obqa_rag\":\n",
    "                            acc_result['num_docs'] = rag_num_docs\n",
    "                        data.append(acc_result)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_path = f\"/home/aiops/zhuty/tinyllama/scripts/fewshot_eval/outputs/BM25Chunk/tweet_hate_24_56_prompts_and_preds.json\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_result = json.load(open(pred_path, 'r'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(pred_result['prompts'][0]['prompt'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_result['preds'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_result['preds'][:100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[x for x in pred_result['preds'] if not x.startswith('Hate')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synpre_env",
   "language": "python",
   "display_name": "synpre_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
